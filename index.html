<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Frank Yu</title>
  
  <meta name="author" content="Frank Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Frank Yu</name>
              </p>
              <p>I am a second year M.Sc. student in Computer Science at the  <a href="https://www.cs.ubc.ca/">University of British Columbia (UBC)</a>, where I am supervised by Prof. <a href="https://www.cs.ubc.ca/~rhodin/">Helge Rhodin</a>. I am expecting to graduate in May 2023 and am currently looking for full-time positions! 
              <p>
              Previously, I had the pleasure of interning with a wonderful group of people at Google (Project Starline). I also completed my B.Sc. in Electrical Engineering at the <a href="http://umanitoba.ca/">University of Manitoba</a>, where I was also an undergraduate research assistant in Prof. <a href="https://www.cs.umanitoba.ca/~ywang/">Yang Wang</a>'s Lab. 
              </p>
              <p style="text-align:center">
                <a href="mailto:frankyu@cs.ubc.ca">Email</a> &nbsp/&nbsp
                <a href="data/CV-Frank Yu.pdf">CV</a> &nbsp/&nbsp       
                <a href="https://scholar.google.com/citations?hl=en&user=q0ZUBN4AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/yu-frank">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/frankyu97/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/_frankyu">Twitter</a> &nbsp/&nbsp
                <a href="https://www.instagram.com/frankjpeg">Photography</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="img/Frank.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="img/Frank_Circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                &nbsp <font color=#FF000><strong>New!</strong></font> June 2022: Started internship (Student Researcher) @ Google (Project Starline)
                <br>
                &nbsp <font color=#FF000><strong>New!</strong></font> September 2022: Paper accepted to WACV 2023
                <br>
                &nbsp <font color=#FF000><strong>New!</strong></font> September 2022: Demo accepted to SIGGRAPH Asia 2023 (E-Tech)
                <br>
                &nbsp <font color=#FF000><strong>New!</strong></font> June 2022: Started internship (Research Intern) @ Google (Project Starline)
                <br>
                <br>
                &nbsp <font color=#FF000></font> September 2021: A-NeRF accepted to NeurIPS 2021 (Poster)
                <br>
                &nbsp <font color=#FF000></font> May 2021: TA'ing CPSC340: Machine Learning and Data Mining
                <br>
                &nbsp <font color=#FF000></font> March 2021: PCL Paper accepted to CVPR 2021 (Poster) 
                <br>
                &nbsp <font color=#FF000></font> January 2021: A-NeRF paper available on arxiv 
                <br>
                &nbsp <font color=#FF000></font> November 2020: I will be a student volunteer at NeurIPS 2020 
                <br>
                &nbsp <font color=#FF000></font> September 2020: Starting my M.Sc in Computer Science at the University of British Columbia 
                <br>
                &nbsp <font color=#FF000></font> August 2020: Paper accepted to ECCV 2020 (Spotlight)
                <br>
                &nbsp <font color=#FF000></font> June 2020: Graduated from the University of Manitoba with a B.Sc in Electrical Engineering
              </p>
            </td>
          </tr>
        </tbody></table>
        
        
        <!-- RESEARCH -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests focus on computer vision and neural rendering. My goal is to develop state-of-the-art technologies that seamlessly bend our world with the virtual world and vice versa.               </p>
            </td>
          </tr>
        </tbody></table>

        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="img/low_latency_overview.png"><img style="width:100%;max-width:100%" alt="profile photo" src="img/low_latency_overview.png" class="hoverZoomLink"></a>
          </td>
        
          <td style="padding:20px;width:75%;vertical-align:middle">              
            <papertitle><font color=#FF000><strong>New!</strong></font>Scaling Neural Face Synthesis to High FPS and Low Latency by Neural Caching</papertitle>
            </a>
            <br>
            <strong>Frank Yu</strong>,
            <a href="https://ece.ubc.ca/sid-fels/">Sid Fels</a>,
            <a href="https://www.cs.ubc.ca/~rhodin/">Helge Rhodin</a>,
            <br>
            <em><font color=#FF8080><strong>WACV 2023</strong></font></em>
            <br>
            <!-- <a href="https:yu-frank.github.io">Paper (Coming Soon)</a> | <a href="./low_latency/index.html">Project Page</a>   -->
            <a href="https://yu-frank.github.io">Paper (Coming Soon)</a> | <a href="https://yu-frank.github.io/lowlatency">Project Page</a>  

            <p></p>
            <p>
              We present a novel method to reduce latency in neural rendering methods for telepresence by caching and implicitly warping neural network features between timesteps.
            </p>
          </td>
          
        </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="img/anerf.gif"><img style="width:100%;max-width:100%" alt="profile photo" src="img/anerf.gif" class="hoverZoomLink"></a>
          </td>
        
          <td style="padding:20px;width:75%;vertical-align:middle">              
            <papertitle>A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering</papertitle>
            </a>
            <br>
            <a href="https://lemonatsu.github.io/">Shih-Yang Su</a>,
            <strong>Frank Yu</strong>,
            <a href="https://zollhoefer.com/">Michael Zollhoefer</a>,
            <a href="https://www.cs.ubc.ca/~rhodin/">Helge Rhodin</a>,
            <br>
            <em><font color=#FF8080><strong>NeurIPS 2021</strong></font></em> (Poster)
            <br>
            <a href="https://arxiv.org/abs/2102.06199">Paper</a> | <a href="https://lemonatsu.github.io/ANeRF-Surface-free-Pose-Refinement/">Project Page</a>  
            <p></p>
            <p>
              We present an analysis-by-synthesis approach for monocular motion capture that learns a volumetric body model and refines the 3D pose estimation of the user in a self-supervised manner.
            </p>
          </td>
          
        </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="img/pcl_overview.png"><img style="width:100%;max-width:100%" alt="profile photo" src="img/pcl_overview.png" class="hoverZoomLink"></a>
          </td>
        
          <td style="padding:20px;width:75%;vertical-align:middle">              
            <papertitle> PCLs: Geometry-aware Neural Reconstruction of 3D Pose with Perspective Crop Layers</papertitle>
            </a>
            <br>
            <strong>Frank Yu</strong>,
            <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a>,
            <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>,
            <a href="https://www.cs.ubc.ca/~rhodin/">Helge Rhodin</a>,
            <br>
            <em><font color=#FF8080><strong>CVPR 2021</strong></font></em> (Poster)
            <br>
            <a href="https://arxiv.org/abs/2011.13607">Paper</a> | <a href="https://github.com/yu-frank/PerspectiveCropLayers">Code</a>
            <p></p>
            <p>
              We propose PCL (perspective crop layer), a set of modular neural network layers that when inserted into MLPs or CNNs will deterministically remove location-dependent perspective effects leading to more precise 3D human pose estimation.
            </p>
          </td>
          
        </tr> 
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="img/Intro.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="img/Intro.jpg" class="hoverZoomLink"></a>
          </td>
        
          <td style="padding:20px;width:75%;vertical-align:middle">              
            <papertitle>Few-shot Scene-adaptive Anomaly Detection</papertitle>
            </a>
            <br>
            <a href="https://cs.uwaterloo.ca/~y485lu/">Yiwei Lu</a>,
            <strong>Frank Yu</strong>,
            <a href="http://www.cs.umanitoba.ca/~kumarkm/">Mahesh Kumar Krishna Reddy</a>,
            <a href="http://www.cs.umanitoba.ca/~ywang/">Yang Wang</a>
            <br>
            <em><font color=#FF8080><strong>ECCV 2020</strong></font></em> (Spotlight)
            <br>
            <a href="https://arxiv.org/abs/2007.07843">Paper</a> |
            <a href="https://github.com/yiweilu3/Few-shot-Scene-adaptive-Anomaly-Detection">Code</a>
            <p></p>
            <p>We propose a more realistic problem setting for anomaly detection in surveillance videos and solve it using a meta-learning based algorithm.</p>
          </td>
          
        </tr>    
        
      <!-- DEMOS -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Demos</heading>
        </td>
      </tr>
    </tbody></table>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <a href="img/televiewdemo.png"><img style="width:100%;max-width:100%" alt="profile photo" src="img/televiewdemo.png" class="hoverZoomLink"></a>
      </td>

      <td style="padding:20px;width:75%;vertical-align:middle">              
        <papertitle><font color=#FF000><strong>New!</strong></font>TeleViewDemo: Experience the Future of 3D Teleconferencing</papertitle>
        </a>
        <br>
        <a>Ziyi Xia</a>,
        <strong>Frank Yu</strong>,
        <a>Beibei Xiong</a>,
        <a>Emily Jia</a>,
        <a>Kaseya Zia</a>,
        <a>Seungyeon Baek</a>,
        <a>James Gregson</a>,
        <a>Xingzhe He</a>,
        <a href="https://www.cs.ubc.ca/~rhodin/">Helge Rhodin</a>,
        <a href="https://ece.ubc.ca/sid-fels/">Sid Fels</a>,
        <br>
        <em><font color=#FF8080><strong>SIGGRAPH Asia 2022 (E-Tech)</strong></font></em>
        <br>
        <a href="https:yu-frank.github.io">Abstract (Coming Soon)</a> | <a href="http://yu-frank.github.io/">Project Page</a>  
        <p></p>
        <p>
          We present an open-source telepresence platform capable of rendering on varioius view-dependent displays including, spherical, head-mounted VR, and flat screens.
        </p>
      </td> 
    </tr>
         
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Teaching</heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="img/ubc.png"><img style="width:100%;max-width:100%" alt="profile photo" src="img/ubc.png" class="hoverZoomLink"></a>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">              
          <papertitle> TA for CPSC340: Machine Learning and Data Mining [Summer 2021]</papertitle>
          <p>
            Led weekly tutorials and office hours. Assisted with assignment and final exam grading.
          </p>
        </td>
        
      </tr> 
           
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Credits to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> for the website design.
               

              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
